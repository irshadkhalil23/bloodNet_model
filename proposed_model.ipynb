{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as npi\n",
    "import seaborn as sns\n",
    "import cv2, os, glob, datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from keras import layers, Input\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.applications import InceptionV3\n",
    "from keras.models import Sequential, Model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from keras.layers import Conv2D, MaxPool2D, Flatten, Dense, Activation, Dropout, GlobalAveragePooling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.applications import ResNet50  # You can switch to other models like VGG16, Xception, etc.\n",
    "\n",
    "inp = 299  \n",
    "model = InceptionV3(weights=\"imagenet\", include_top=False, input_shape=(inp, inp, 3))\n",
    "\n",
    "# Folder paths\n",
    "folders = glob.glob(r\"D:\\adnan blood detection2\\*\")\n",
    "\n",
    "# Initialize lists for storing images and labels\n",
    "img_list = []\n",
    "label_list = []\n",
    "\n",
    "# Loop through the folders and read images\n",
    "for folder in folders:\n",
    "    print(f\"Processing folder: {folder}\")\n",
    "    \n",
    "    # Read both .png and .jpg images\n",
    "    image_paths = glob.glob(folder + r\"/*.jpg\") + glob.glob(folder + r\"/*.png\")\n",
    "    \n",
    "    if not image_paths:\n",
    "        print(f\"No images found in {folder}\")\n",
    "    \n",
    "    for img in image_paths:\n",
    "        n = cv2.imread(img)\n",
    "        if n is None:\n",
    "            print(f\"Failed to read image: {img}\")\n",
    "            continue\n",
    "        \n",
    "        class_num = folders.index(folder)  # Assign label based on folder index\n",
    "        label_list.append(class_num)\n",
    "        \n",
    "        # Resize image to the required size for ResNet50 (224x224)\n",
    "        resized = cv2.resize(n, (inp, inp), interpolation=cv2.INTER_AREA)\n",
    "        img_list.append(resized)\n",
    "\n",
    "# Check if img_list and label_list are populated\n",
    "if not img_list or not label_list:\n",
    "    raise ValueError(\"No images found. Check the paths and image files.\")\n",
    "\n",
    "# Split data into training (70%) and testing (30%) sets\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(img_list, label_list, test_size=0.3, random_state=1)\n",
    "X_valid, X_test, y_valid, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=1)\n",
    "\n",
    "# Convert lists to numpy arrays\n",
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train)\n",
    "X_valid = np.array(X_valid)\n",
    "y_valid = np.array(y_valid)\n",
    "X_test = np.array(X_test)\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "# Print the shapes of the datasets\n",
    "print(\"training_set\", X_train.shape)\n",
    "print(\"training_set\", y_train.shape)\n",
    "print(\"validation_set\", X_valid.shape)\n",
    "print(\"validation_set\", y_valid.shape)\n",
    "print(\"test_set\", X_test.shape)\n",
    "print(\"test_set\", y_test.shape)\n",
    "\n",
    "# Count the number of images for each class in the entire dataset\n",
    "unique_classes, class_counts = np.unique(label_list, return_counts=True)\n",
    "\n",
    "# Create a bar chart to visualize the number of images for each class\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(unique_classes, class_counts, color='skyblue')\n",
    "\n",
    "# Labeling the chart\n",
    "plt.xlabel('Class Index')\n",
    "plt.ylabel('Number of Images')\n",
    "plt.title('Number of Images in Each Class')\n",
    "\n",
    "# Add labels on top of each bar\n",
    "for i, count in enumerate(class_counts):\n",
    "    plt.text(i, count + 10, str(count), ha='center', fontsize=12)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.applications import ResNet50  # You can switch to other models like VGG16, Xception, etc.\n",
    "\n",
    "# Initialize the model\n",
    "inp = 224  # ResNet50 requires input shape (224, 224, 3)\n",
    "model = ResNet50(weights=\"imagenet\", include_top=False, input_shape=(inp, inp, 3))\n",
    "\n",
    "# Folder paths\n",
    "folders = glob.glob(r\"D:\\adnan blood detection2\\*\")\n",
    "\n",
    "# Initialize lists for storing images and labels\n",
    "img_list = []\n",
    "label_list = []\n",
    "\n",
    "# Loop through the folders and read images\n",
    "for folder in folders:\n",
    "    print(f\"Processing folder: {folder}\")\n",
    "    \n",
    "    # Read both .png and .jpg images\n",
    "    image_paths = glob.glob(folder + r\"/*.jpg\") + glob.glob(folder + r\"/*.png\")\n",
    "    \n",
    "    if not image_paths:\n",
    "        print(f\"No images found in {folder}\")\n",
    "    \n",
    "    for img in image_paths:\n",
    "        n = cv2.imread(img)\n",
    "        if n is None:\n",
    "            print(f\"Failed to read image: {img}\")\n",
    "            continue\n",
    "        \n",
    "        class_num = folders.index(folder)  # Assign label based on folder index\n",
    "        label_list.append(class_num)\n",
    "        \n",
    "        # Resize image to the required size for ResNet50 (224x224)\n",
    "        resized = cv2.resize(n, (inp, inp), interpolation=cv2.INTER_AREA)\n",
    "        img_list.append(resized)\n",
    "\n",
    "# Check if img_list and label_list are populated\n",
    "if not img_list or not label_list:\n",
    "    raise ValueError(\"No images found. Check the paths and image files.\")\n",
    "\n",
    "# Split data into training (70%) and testing (30%) sets\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(img_list, label_list, test_size=0.3, random_state=1)\n",
    "X_valid, X_test, y_valid, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=1)\n",
    "\n",
    "# Convert lists to numpy arrays\n",
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train)\n",
    "X_valid = np.array(X_valid)\n",
    "y_valid = np.array(y_valid)\n",
    "X_test = np.array(X_test)\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "# Print the shapes of the datasets\n",
    "print(\"training_set\", X_train.shape)\n",
    "print(\"training_set\", y_train.shape)\n",
    "print(\"validation_set\", X_valid.shape)\n",
    "print(\"validation_set\", y_valid.shape)\n",
    "print(\"test_set\", X_test.shape)\n",
    "print(\"test_set\", y_test.shape)\n",
    "print(\"Train_Folder\", len(X_train))\n",
    "print(\"validation_Folder\", len(X_valid))\n",
    "print(\"Test_Folder\", len(X_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs =Input((inp, inp, 3))\n",
    "X = model(inputs)\n",
    "flat1 = GlobalAveragePooling2D()(X)\n",
    "x3=layers.GlobalMaxPooling2D()(X)\n",
    "x1=layers.Dense(100, activation='relu')(flat1)\n",
    "x1=layers.Dense(50, activation='relu')(x1)\n",
    "x1=layers.BatchNormalization()(x1)\n",
    "\n",
    "x2=layers.Conv2D(filters = 64,kernel_size = (1,1), activation='relu', padding='same')(X)\n",
    "x2=layers.Conv2D(filters = 64,kernel_size = (7,7), activation='relu', padding='same')(x2)\n",
    "x2=layers.Conv2D(filters = 64,kernel_size = (1,1), activation='relu', padding='same')(x2)\n",
    "\n",
    "x2=layers.GlobalAveragePooling2D()(x2)\n",
    "x2=layers.BatchNormalization()(x2)\n",
    "\n",
    "BAM=layers.concatenate([x1, x2])\n",
    "BAM=layers.BatchNormalization()(BAM)\n",
    "BAM=layers.concatenate([x3, BAM])\n",
    "\n",
    "F=layers.Dense(150, activation='relu')(BAM)\n",
    "F=layers.BatchNormalization()(F)\n",
    "output = Dense(3,activation='softmax')(F)\n",
    "model = Model(inputs=inputs, outputs=output)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "epochs = 30\n",
    "opt = SGD(learning_rate=0.0001, momentum=0.9)\n",
    "model.compile(optimizer=opt, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "history=model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs,verbose=1,validation_data=(X_valid,y_valid))\n",
    "model.save(\"adxnan1.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "epochs = 30\n",
    "opt = SGD(learning_rate=0.0001, momentum=0.9)\n",
    "model.compile(optimizer=opt, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "history=model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs,verbose=1,validation_data=(X_valid,y_valid))\n",
    "model.save(\"adxnan1.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import  confusion_matrix\n",
    "import matplotlib.pyplot as plot\n",
    "import seaborn as sn\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import  confusion_matrix\n",
    "from sklearn.metrics import classification_report \n",
    "import numpy as np\n",
    "plt.figure(figsize=(30,30))\n",
    "sns.set(font_scale=1.0)\n",
    "\n",
    "f, ax = plt.subplots()\n",
    "ax.plot([None] + history.history['accuracy'])\n",
    "ax.plot([None] + history.history['val_accuracy'])\n",
    "# Plot legend and use the best location automatically: loc = 0.\n",
    "ax.legend(['Train acc', 'Val acc'], loc = 0)\n",
    "ax.set_title('Training/Validation acc per Epoch')\n",
    "ax.set_xlabel('Epoch')\n",
    "ax.set_ylabel('Accuracy')\n",
    "f, ax = plt.subplots()\n",
    "ax.plot([None] + history.history['loss'])\n",
    "ax.plot([None] + history.history['val_loss'])\n",
    "# Plot legend and use the best location automatically: loc = 0.\n",
    "ax.legend(['Train loss', \"Val loss\"], loc = 1)\n",
    "ax.set_title('Training/Validation Loss per Epoch')\n",
    "ax.set_xlabel('Epoch')\n",
    "ax.set_ylabel('Loss')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "y_pred=model.predict(X_test)\n",
    "y_pred=np.argmax(y_pred, axis=1)\n",
    "\n",
    "target_names = [\"Scene 1\",\"Scene 2\",\"Scene 3\"] \n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(\"***** Confusion Matrix *****\")\n",
    "print(cm)\n",
    "print(\"***** Classification Report *****\")\n",
    "print(classification_report(y_test, y_pred, target_names=target_names))\n",
    "classes=3\n",
    "con = np.zeros((classes,classes))\n",
    "for x in range(classes):\n",
    "    for y in range(classes):\n",
    "        con[x, y] = cm[x, y] / np.sum(cm[x, :]) * 100  # Calculate percentage\n",
    "\n",
    "plt.figure(figsize=(15, 12))\n",
    "df = sns.heatmap(con, annot=True, fmt='.2f', cmap='Blues', xticklabels=target_names, yticklabels=target_names)\n",
    "df.figure.savefig(\"Model.png\")\n",
    "plt.show()\n",
    "print('\\nTesting loss: {:.4f}\\nTesting accuracy: {:.4f}'.format(*model.evaluate(X_test, y_test)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
